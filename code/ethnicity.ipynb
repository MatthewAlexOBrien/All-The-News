{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ethnicity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNlhK8Q68knEYfkbg7GsAUs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatthewAlexOBrien/All-The-News/blob/master/code/ethnicity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ****Identifying Race and Gender****\n",
        "\n",
        "See: ***ethnicity.ipnyb*** \n",
        "\n",
        "Race of named subjects is identified with two methods. \n",
        "* i. DEEP FACE We use google images and DeepFace https://pypi.org/project/deepface/ to measure ethnicity and gender, which has an overall accuracy of 97% for predicting gender and 72% for predicting race. We obtain images of named subjects by 'googling' them and dowloading the first 4 images. \n",
        "\n",
        "* ii. ETHNICOLR We use the ethnicolr package https://ethnicolr.readthedocs.io/ethnicolr.html to predict race based on the letter sequences in the subjects' name. The authors of this package have a corresponding paper https://arxiv.org/pdf/1805.02109.pdf which outlines their procedure for predicting race. They use voter registration data in the US to train deep neural models that identify letter sequences that most correspond to specific ethnic origins.  The measure privides 85% accuracy when both the first and last name are identified. "
      ],
      "metadata": {
        "id": "Wd9K7_csy-Aj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHNU8d8l2Ajv"
      },
      "source": [
        "**Install and Import Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lil2uXTZ2LMK"
      },
      "source": [
        "%%capture\n",
        "\n",
        "# Packages not pre-install on Python 3.7\n",
        "!pip3 install ethnicolr\n",
        "!pip3 install cv2\n",
        "!pip3 install deepface\n",
        "!pip3 install google_images_download"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmsjC47F_iBj"
      },
      "source": [
        "%%capture\n",
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "from google_images_download import google_images_download \n",
        "import cv2\n",
        "import random \n",
        "from deepface import DeepFace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KrNT5roBzmb"
      },
      "source": [
        "**Static Functions**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Method take a given search query on google and download the first n number of images.\n",
        "def downloadimages(query, n=3):\n",
        "    arguments = {\"keywords\": query,\n",
        "                 \"format\": \"jpg\",\n",
        "                 \"limit\":n,\n",
        "                 \"print_urls\":True,\n",
        "                 \"size\": \"medium\"}\n",
        "    try:\n",
        "        response.download(arguments)\n",
        "    except:\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "iah2Ar6A0wiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1EROT7ixxie"
      },
      "source": [
        "**Import and Clean Data**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "path = '.../Sentences'\n",
        "all_files = glob.glob(path + \"/*.csv\")\n",
        "li = []\n",
        "\n",
        "# concatenating sentence dataframes together\n",
        "for filename in all_files:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0)\n",
        "    li.append(df)\n",
        "\n",
        "# basic cleaning\n",
        "sentences = pd.concat(li, axis=0, ignore_index=True)\n",
        "sentences = sentences[['year', 'month', 'day', 'publication', 'article_id', 'sentence_id', 'sentence', 'sentence_subject_names']]\n",
        "sentences['sentence_subject_names'] = sentences['sentence_subject_names'].replace(r'[\\[|\\]|\\']', '', regex=True)\n",
        "sentences = sentences[sentences['sentence_subject_names'].map(lambda d: len(d.split(','))) ==1 ]"
      ],
      "metadata": {
        "id": "7nBtxgQy1NN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht4cZWAt1xhJ"
      },
      "source": [
        "**Get Images of Subjects From Google**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list of names to extract images for\n",
        "names = sentences['sentence_subject_names'].unique()\n",
        "\n",
        "# inputs\n",
        "response = google_images_download.googleimagesdownload()\n",
        "cascPath = \".../python3.7/site-packages/cv2/data/haarcascade_frontalface_default.xml\"\n",
        "faceCascade = cv2.CascadeClassifier(cascPath)"
      ],
      "metadata": {
        "id": "Wxl1pdhM2FwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download images from each name, keeping only images with exactly 1 face\n",
        "for name in names_small:\n",
        "    \n",
        "    # dowloading image\n",
        "    try:\n",
        "        downloadimages(name, n=4) \n",
        "        print()\n",
        "    except:\n",
        "        print('issue with ' + str(name))\n",
        "    \n",
        "    # get list of jpg doloaded images for each name\n",
        "    folder =str(os.getcwd()) + '/downloads/' + str(name) + '/' \n",
        "    files = glob.glob(folder + \"/*\")\n",
        "    \n",
        "    # check if each image has exactly 1 face\n",
        "    if files:\n",
        "        for file in files:\n",
        "            image_path = file\n",
        "            image = cv2.imread(image_path)\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            faces = faceCascade.detectMultiScale(\n",
        "                gray,\n",
        "                scaleFactor=1.1,\n",
        "                minNeighbors=5,\n",
        "                minSize=(30, 30),\n",
        "                flags=cv2.CASCADE_SCALE_IMAGE\n",
        "            )\n",
        "            num_faces = len(faces)\n",
        "            if num_faces != 1:\n",
        "                os.remove(image_path)\n",
        "            else:\n",
        "                pass    \n",
        "            \n",
        "        # if we get more then 2 clean images, randomly keep only 2\n",
        "        files_clean = glob.glob(folder + \"/*\")\n",
        "        if len(files_clean) >2:\n",
        "            keep_images = random.sample(files_clean, 2)\n",
        "            drop_images = [drop for drop in files_clean if drop not in keep_images]\n",
        "            if drop_images:\n",
        "                for drop_image in drop_images:\n",
        "                    os.remove(drop_image)\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "        else:\n",
        "            pass\n",
        "    else:\n",
        "        pass\n",
        "    "
      ],
      "metadata": {
        "id": "eKaxhZjc2Pdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYdhLLIn2ayU"
      },
      "source": [
        "**Get Gender and Race**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initiate new dataframe of names\n",
        "names_df = pandas.DataFrame(columns=['sentence_subject_names', 'distance', 'gender', 'dominant_race', 'dominant_race_pct', 'white_pct'])\n",
        "\n",
        "\n",
        "# get race, gender, and match % of each name\n",
        "for name in names_small:\n",
        "    image_folder = str(os.getcwd()) + '/downloads/' + name + '/'\n",
        "    images = glob.glob(image_folder + \"/*\") \n",
        "    \n",
        "    # getting distance metric between the two images\n",
        "    try:\n",
        "        if len(images) == 2:\n",
        "            image_path_1 = images[0]\n",
        "            image_path_2 = images[1]\n",
        "            verify = DeepFace.verify(image_path_1,image_path_2)\n",
        "            distance = verify['distance']\n",
        "        else:\n",
        "            distance = numpy.nan\n",
        "    except:\n",
        "        print('issue with verifying ' + name)\n",
        "        distance = numpy.nan\n",
        "        \n",
        "    # getting race and gender\n",
        "    try:\n",
        "        result = DeepFace.analyze(image_path_1, actions = ['gender', 'race'])\n",
        "        gender, dominant_race = result['gender'], result['dominant_race']\n",
        "        dominant_race_pct, white_pct = result['race'][dominant_race], result['race']['white']\n",
        "\n",
        "    except:\n",
        "        print('issue with image ' + name)\n",
        "        gender, race_pct, dominant_race, dominant_race_pct, white_pct = numpy.nan, numpy.nan, numpy.nan, numpy.nan, numpy.nan\n",
        "        \n",
        "    # appending into dataframe\n",
        "    names_df.loc[-1] = [name, distance, gender, dominant_race, dominant_race_pct, white_pct]\n",
        "    names_df.index = names_df.index + 1\n",
        "    names_df = names_df.sort_index()"
      ],
      "metadata": {
        "id": "iTX2DHgx2nM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merging race and gender to sentence dataframe\n",
        "sentences = sentences.merge(names_df, on='sentence_subject_names', how='left')"
      ],
      "metadata": {
        "id": "R_iWKi5w2vXI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}